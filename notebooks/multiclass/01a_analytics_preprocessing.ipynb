{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"../data/raw/train.csv\"\n",
    "PROC_TRAIN_DATA_PATH = \"../data/interim/1__analytics_preprocessed_df.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some pandas display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"styler.format.precision\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_train = pd.read_csv(TRAIN_DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cols = ['sex', 'chest pain type', 'fasting blood sugar', 'resting electrocardiographic', 'exercise induced angina'\n",
    "    , 'slope peak exercise ST segment', 'number of major vessels','thallium stress result']\n",
    "\n",
    "# Get the values count for each feature in the DataFrame\n",
    "def get_values_count(data:pd.DataFrame, cols:list) -> None:\n",
    "    \"\"\"\n",
    "    Calculate the values count for each feature in the DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "    cols : list of features\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    values_count : DataFrame contains values count for each feature\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        print(f\"{col} :{data[col].value_counts(dropna=False).to_dict()}\")\n",
    "\n",
    "def get_unique_values(data:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get unique values in each feature\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values : DataFrame contains unique values for each feature\n",
    "    \"\"\"\n",
    "\n",
    "    uniques = pd.DataFrame(data={\n",
    "        'feature':[],\n",
    "        'uniques':[]\n",
    "    })\n",
    "  \n",
    "    for col in data.columns:\n",
    "        unique_values = data[col].unique()\n",
    "        if(len(unique_values)>1000):\n",
    "            continue\n",
    "\n",
    "        uniques.loc[len(uniques)] = [col, unique_values]\n",
    "    \n",
    "    uniques.index = uniques['feature']\n",
    "    uniques.drop(columns='feature', inplace=True)\n",
    "    return uniques\n",
    "\n",
    "def get_strange_values(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get strange values in each feature\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values : DataFrame contains unique values for each feature\n",
    "    \"\"\"\n",
    "\n",
    "    data_copy = data.copy()\n",
    "    uniques = pd.DataFrame(data={\n",
    "        'feature':[],\n",
    "        'indices-values':[]\n",
    "    })\n",
    "  \n",
    "    for col in data_copy.columns:\n",
    "        # Change the column values to be object for applying Regex\n",
    "        data_copy[col] = data_copy[col].astype(str)\n",
    "\n",
    "        # The pattern for checking the presence of strange values\n",
    "        pattern = \"([+-]?([0-9]+([.][0-9]*)?|[.][0-9]+)|[a-zA-Z]+)\"\n",
    "\n",
    "        # Get mask matrix that refers to strange values ([~]: for not contain)\n",
    "        strange_values_mask = ~data_copy[col].str.contains(pat=pattern, na=True, regex=True, case=False)\n",
    "        \n",
    "        # Get index of the strange values\n",
    "        strange_values_ind = data_copy[strange_values_mask].index.to_list()\n",
    "\n",
    "        # if the indices are empty check \n",
    "        if(not strange_values_ind):\n",
    "            continue\n",
    "        \n",
    "        # dictionary = {\n",
    "        #     col : {ind:list(data_copy.loc[ind,col]) for ind in strange_values_ind}\n",
    "        # }\n",
    "\n",
    "        # reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.items() for innerKey, values in innerDict.items()}\n",
    "        # reform = pd.DataFrame.from_dict(reform, orient='index').transpose()\n",
    "\n",
    "\n",
    "        uniques.loc[len(uniques)] = [col, [(ind, data_copy.loc[ind,col]) for ind in strange_values_ind]]\n",
    "    \n",
    "\n",
    "\n",
    "    uniques.set_index(keys=['feature'], inplace=True)\n",
    "\n",
    "\n",
    "    if(not uniques.empty):\n",
    "        return uniques\n",
    "    \n",
    "    return \"No strange values found!\"\n",
    "    \n",
    "get_strange_values(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all '?' values with NaN\n",
    "train_data.replace('?', np.nan, inplace=True)\n",
    "test_data.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "Since **number of major vessels** & **thallium stress result** are categorical features, the missing values could be replaced by most mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values if exist\n",
    "print(f\"--Missing values count--\\n{train_data.isnull().sum().sort_values()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values from training set\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data[['thallium stress result','number of major vessels']] = mode_imputer.fit_transform(train_data[['thallium stress result','number of major vessels']])\n",
    "test_data[['thallium stress result','number of major vessels']] = mode_imputer.transform(test_data[['thallium stress result','number of major vessels']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame):\n",
    "    data_copy = data.copy()\n",
    "    \"\"\" Remove duplicates values if exist\"\"\"\n",
    "    print(f\"Duplicates count before droping:{data_copy.duplicated().sum()}\")\n",
    "    data_copy.drop_duplicates(inplace=True)\n",
    "    print(f\"Duplicates count after droping:{data_copy.duplicated().sum()}\")\n",
    "    print(f\"Data dimension{data.shape}\")\n",
    "\n",
    "remove_duplicates(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing\n",
    "Check if the training data is well balanced because one of the major issues when dealing with unbalanced datasets relates to the metrics used to evaluate a model. Using simpler metrics like accuracy_score can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory.\n",
    "\n",
    "Depending on the obtained result, the data is well balanced and no need to resample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_balancing(data, target_name):\n",
    "    \"\"\"\n",
    "    Check if the target's classes are balanced between each other\n",
    "    \"\"\"\n",
    "    # return data[target_name].value_counts(normalize=normalize)\n",
    "\n",
    "    #Target Class count\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.pie(data[target_name].value_counts(), labels=['no disease', 'LAD','LCX', 'RCA', 'highest'], autopct='%1.2f%%', explode=[0,0.2,0.2,0.2,0.2], shadow=True)\n",
    "\n",
    "    my_circle = plt.Circle( (0,0), 0.4, color='white')\n",
    "    p = plt.gcf()\n",
    "    p.gca().add_artist(my_circle)\n",
    "    plt.title('Target Class Count')\n",
    "\n",
    "check_balancing(train_data, 'target')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers to String\n",
    "Changing categorical features that contain numbers to be in string format\n",
    "\n",
    "| Attribute   | Updated Feature Values \n",
    "| :-- | :-- \n",
    "|**sex** |0:female<br>1:male|\n",
    "|**chest pain type** | 1:typical angina<br>2:atypical angina<br>3:non-anginal<br>4:asymptomatic|\n",
    "|**fasting blood sugar** |0:> 120 mg/dl<br>1:< 120 mg/dl|\n",
    "|**resting electrocardiographic** |0:normal<br>1:ST-T wave abnormality<br>2:ventricular hypertrophy|\n",
    "|**exercise induced angina** |0:no<br>1:yes|\n",
    "|**slope peak exercise ST segment** |1:upsloping<br>2:flat<br>3:downsloping|\n",
    "|**thallium stress result** |3:normal<br>6:fixed defect<br>7:reversible defect|\n",
    "|**target** |0:no disease<br>1:LAD<br>2:LCX<br>3:RCA<br>4:highest|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numeric\n",
    "train_data = train_data.apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "train_w_cat_data = train_data.copy()\n",
    "\n",
    "train_w_cat_data['sex'] = train_w_cat_data['sex'].map({0:'female', 1:'male'})\n",
    "train_w_cat_data['chest pain type'] = train_w_cat_data['chest pain type'].map({\n",
    "        1:'typical angina', 2:'atypical angina',\n",
    "        3:'non-anginal',    4:'asymptomatic'})\n",
    "train_w_cat_data['fasting blood sugar'] = train_w_cat_data['fasting blood sugar'].map({\n",
    "        0:'> 120 mg/dl', 1:'< 120 mg/dl'})\n",
    "train_w_cat_data['resting electrocardiographic'] = train_w_cat_data['resting electrocardiographic'].map({\n",
    "        0:'normal', 1:'ST wave abnormality', 2:'ventricular hypertrophy'})\n",
    "train_w_cat_data['exercise induced angina'] = train_w_cat_data['exercise induced angina'].map({\n",
    "        0:'no', 1:'yes'})\n",
    "train_w_cat_data['slope peak exercise ST segment'] = train_w_cat_data['slope peak exercise ST segment'].map({\n",
    "        1:'upsloping', 2:'flat', 3:'downsloping'})\n",
    "\n",
    "train_w_cat_data['thallium stress result'] = train_w_cat_data['thallium stress result'].map({\n",
    "        3:'normal', 6:'fixed defect', 7:'reversible defect'})\n",
    "\n",
    "train_w_cat_data['target'] = train_w_cat_data['target'].map({0:'no disease', 1:'LAD',\n",
    "        2:'LCX', 3:'RCA', 4:'highest'})\n",
    "\n",
    "train_w_cat_data.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(PROC_TRAIN_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafb1f7618ea635952683f9de1ec2ad0605097bc28573cb02814b9f97cdb4857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
